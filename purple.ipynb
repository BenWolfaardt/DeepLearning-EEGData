{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold: 1/3\n",
      "Training new iteration on 199 training samples, 101 validation samples, this may be a while...\n",
      "Train on 199 samples, validate on 101 samples\n",
      "Epoch 1/200\n",
      "100/199 [==============>...............] - ETA: 1:49 - loss: 1.1560 - acc: 0.3100"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Oct  1 22:10:52 2018\n",
    "\n",
    "@author: Ben\n",
    "\"\"\"\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import TensorBoard , EarlyStopping\n",
    "import itertools\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "#import itertools\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "NAME = \"CNN train 20 2 Architecture\"\n",
    "# Loading training data from preprocessing\n",
    "# Change these numbers\n",
    "pickle_in = open(\"X_train_20_2.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "pickle_in = open(\"y_train_20_2.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "# Change these numbers\n",
    "pickle_in = open(\"X_test_20_2.pickle\",\"rb\")\n",
    "X_test = pickle.load(pickle_in)\n",
    "pickle_in = open(\"y_test_20_2.pickle\",\"rb\")\n",
    "y_test = pickle.load(pickle_in)\n",
    "\n",
    "CATEGORIES = ['Lavendar','Full Screen','Word']\n",
    "\n",
    "# KFold pick your folds here\n",
    "kfold_splits=3\n",
    "skf = StratifiedKFold(n_splits=kfold_splits, shuffle=True)\n",
    "y = np.transpose(y)\n",
    "\n",
    "def create_model():\n",
    "    # Give it unique name for tensorboard and also save\n",
    "   \n",
    "    model = Sequential()\n",
    "         \n",
    "    model.add(Conv2D(512, (3, 3), input_shape=X.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(512, (3, 3)))\n",
    "    model.add(Activation('relu')) \n",
    "    \n",
    "    model.add(Conv2D(256, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Conv2D(48, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "        \n",
    "    model.add(Flatten())   \n",
    "    \n",
    "    model.add(Dense(36))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(18))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2)) \n",
    "    \n",
    "    # Last dense 1ayers must have number of classes in data in the parenthesis\n",
    "    # Also must be softmax\n",
    "    model.add(Dense(3))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train_model(model,xtrain,ytrain,xval,yval):\n",
    "                \n",
    "    # Preventing overfitting through 'earlystopping' it will monitor val_loss and stop\n",
    "    # computing when val_loss goes up even though there are more epochs\n",
    "      earlystopping = EarlyStopping(monitor= 'val_loss',\n",
    "                                    min_delta = 0, \n",
    "                                    patience= 2, \n",
    "                                    verbose = 0, \n",
    "                                    mode ='auto'\n",
    "                                    )\n",
    "    \n",
    "    accuracy= model.fit(xtrain,ytrain,\n",
    "              epochs = 8, \n",
    "              validation_data= (xval,yval),\n",
    "              batch_size=10,\n",
    "              shuffle=True\n",
    "              )    \n",
    "    return accuracy\n",
    "\n",
    "Total_accuracy = []\n",
    "for index, (train_indices, val_indices) in enumerate(skf.split(X,y)):\n",
    "    print(\"Training on fold: \" + str(index+1)+\"/{}\".format(kfold_splits))\n",
    "    \n",
    "    #Generate batches\n",
    "    xtrain, xval = X[train_indices], X[val_indices]\n",
    "    ytrain, yval = y[train_indices], y[val_indices]\n",
    "\n",
    "    # Clear model, and create it\n",
    "    model = None\n",
    "    model = create_model()\n",
    "\n",
    "    # Debug message I guess\n",
    "    print (\"Training new iteration on \" + str(xtrain.shape[0]) + \" training samples, \" \n",
    "    + str(xval.shape[0]) + \" validation samples, this may be a while...\")\n",
    "    \n",
    "    \n",
    "    history = train_model(model, xtrain, ytrain, xval, yval)\n",
    "    accuracy_history = history.history['acc']\n",
    "    val_accuracy_history = history.history['val_acc']\n",
    "    print (\"Last training accuracy: \" + str(accuracy_history[-1]) \n",
    "    + \", last validation accuracy: \" + str(val_accuracy_history[-1]))\n",
    "    \n",
    "    \n",
    "    Total_accuracy.append(val_accuracy_history[-1])\n",
    "\n",
    "accuracy_Array = np.asarray(Total_accuracy)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(accuracy_Array*100), np.std(accuracy_Array*100)))\n",
    "print(accuracy_Array)\n",
    "\n",
    "# model = model_load(NAME)\n",
    "model.save(NAME)\n",
    "\n",
    "# Loading the trained model for testing \n",
    "#model = load_model(\"NAME\")\n",
    "\n",
    "# Letting the above trained model predict on unseen data \n",
    "prediction = model.predict(X_test, batch_size=10, verbose=0)\n",
    "# Visualizing these predictions\n",
    "for i in prediction:\n",
    "    print(i)\n",
    "\n",
    "# Rounding the prediction to the classes\n",
    "rounded_prediction = model.predict_classes(X_test, batch_size=10, verbose=0)\n",
    "# Visualizing the best model\n",
    "for i in rounded_prediction:\n",
    "    print(i)\n",
    "\n",
    "# Confusion matrix to visualize how the model was performing SKLEARN\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float32') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, rounded_prediction)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=CATEGORIES,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=CATEGORIES, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "plt.show()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
